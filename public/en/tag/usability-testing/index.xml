<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Usability Testing | Rozum S, UXR</title>
    <link>/en/tag/usability-testing/</link>
      <atom:link href="/en/tag/usability-testing/index.xml" rel="self" type="application/rss+xml" />
    <description>Usability Testing</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>2025</copyright><lastBuildDate>Sat, 18 May 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu19a1120d39a533b4446980715d7e8190_15602_512x512_fill_lanczos_center_2.png</url>
      <title>Usability Testing</title>
      <link>/en/tag/usability-testing/</link>
    </image>
    
    <item>
      <title>The Ideal Usability Issue</title>
      <link>/en/post/ideal-usability-problem/</link>
      <pubDate>Sat, 18 May 2024 00:00:00 +0000</pubDate>
      <guid>/en/post/ideal-usability-problem/</guid>
      <description>&lt;p&gt;&lt;em&gt;There can never be too many articles dedicated to fundamental topics. That’s why I also decided to dig into the well-worn and widely known subject. Today we’ll talk about the canonical definition and description of a usability issue.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This article deliberately avoids case studies and examples because, right now, it’s especially important to focus on the fundamental principles of usability testing without delving into isolated examples.&lt;/p&gt;
&lt;p&gt;Why do I think this is important? Usability testing is a research method with surprisingly few ambiguities. It is very limited and straightforward, but it is precisely in these limitations that its strength lies. The same applies to its results; we can very clearly define what a usability issue is and how to describe it.&lt;/p&gt;
&lt;p&gt;However, we often feel that we can use this method to cover more than it’s intended for. Such blurring can strip the method of its strengths and reduce trust in our research.&lt;/p&gt;
&lt;h2 id=&#34;features-of-usability-testing-as-a-method&#34;&gt;Features of Usability Testing as a Method&lt;/h2&gt;
&lt;p&gt;In usability testing, we have a clearly defined object of study — the interface. Our goals and objectives are also unambiguous — we are looking for usability issues encountered by users and measuring the usability of the product being tested.&lt;/p&gt;
&lt;p&gt;Because the object of usability testing is the interface, we can make strong conclusions with a small sample size. We don’t need to worry much about the validity of results, as we’re not studying opinions but the interface itself. We literally see the interface features that lead to problems during the test and understand that they need to be addressed in some way.&lt;/p&gt;
&lt;p&gt;By limiting the scope of the research, we gain a unique advantage in qualitative studies. Our conclusions are far less speculative; we have solid, rigorous arguments. This narrow focus allows us to make conclusions with a sample size that would be microscopic for any other study.&lt;/p&gt;
&lt;p&gt;Most criticism of usability testing results stems from a lack of understanding of these method features. “Can we really trust these participants? Sure, they say it’s inconvenient, but it’s just two people,” or, “How can we be sure other users will encounter the same issues? Maybe your participants are just not smart.” All of this is meaningless if we understand that usability testing evaluates not users, not even their behavior, but the interface. Mistakes made by participants during the test help us identify interface elements that may cause problems in real-world use and understand why they occur. In usability testing, the participant acts as a tool, helping us evaluate the interface.&lt;/p&gt;
&lt;p&gt;However, if we shift the research focus from the interface to the user, problems begin to arise. As a method, usability testing has simple sampling requirements but very limited capacity for studying user opinions and behavior. If we try to study users using this method, our sample size increases, we need to create a 4–8-window structure, and our scenario becomes more complex with added variability. This complicates the analysis, increases our report size, and effectively turns the study into in-depth interviews with elements of usability testing, rather than usability testing itself. This significantly impacts the timelines and costs of the research.&lt;/p&gt;
&lt;p&gt;Alternatively, we might not modify the test methodology but attempt to work with participants and results as if conducting in-depth interviews. This approach likely fails to reach data saturation, resulting in shaky foundations for conclusions that are over-extrapolated. Ultimately, this diminishes the value of the research and undermines its validity in the eyes of stakeholders.&lt;/p&gt;
&lt;p&gt;Therefore, to fully leverage the strengths of usability testing — speed, simplicity, low sample requirements, and clear, unambiguous results — we must consciously keep our research focus under control.&lt;/p&gt;
&lt;h2 id=&#34;results-in-usability-testing&#34;&gt;Results in Usability Testing&lt;/h2&gt;
&lt;p&gt;In usability testing, we must always distinguish between primary and secondary results. The primary result of usability testing is always a set of usability issues. It may also include insights into the overall usability of the product but nothing more. User expectations, feature requests, product opinions, and usage patterns are also incredibly important, but they are secondary in this particular study. To explore them, we need to use a more appropriate research method. Usability testing will not provide sufficiently strong results in these areas — at most, it will generate hypotheses and ideas for subsequent, more methodologically valid studies.&lt;/p&gt;
&lt;p&gt;This brings us to the idea of the ideal usability issue description.&lt;/p&gt;
&lt;p&gt;To describe the ideal usability issue, we turn to the classic definition of usability:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction in a specified context of use.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From this definition, we can derive the definition of a usability issue:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A usability issue is a feature of the interface that hinders the effective and efficient completion of user tasks and reduces user satisfaction with the system.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This definition is important because it also allows us to outline what a usability issue is not:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A usability issue cannot be the lack of desire to perform an action in the product.&lt;/strong&gt; It cannot manifest as a user not wanting to do something. We deliberately narrow our focus in usability testing to exclude questions of willingness to use a product or its features. Studying feature demand is more complex than studying usability and requires a different research method.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A usability issue cannot be a bug&lt;/strong&gt; because a bug is inherently incorrect system behavior. If we try to study bugs or technical system properties (e.g., data loading speed, animation performance) through usability testing, we risk drawing conclusions from an inherently flawed sample. Proper technical testing requires a dedicated device setup and specialized testing methods. That’s why QA testing is often a separate function in a company, operating on a different principle than usability testing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A usability issue cannot be a lack of functionality.&lt;/strong&gt; In usability testing, we study the ease of use of existing product features. We may receive comments about missing features, but these should always serve as a basis for further research, not as standalone results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A usability issue is not the absence of a solution&lt;/strong&gt; because a problem is a problem, not the absence of a solution. This distinction is subtle. A usability issue is a property of the interface, an element that hinders product use. If we frame a problem as “Feature X is missing,” we miss the opportunity to address the usability issue in other ways. It’s like going to a doctor and saying, “I lack painkillers” instead of “I have a headache.” While technically possible, this approach limits us to one solution that may not be the best.&lt;/p&gt;
&lt;h2 id=&#34;the-ideal-usability-issue&#34;&gt;The Ideal Usability Issue&lt;/h2&gt;
&lt;p&gt;Based on all the above, we can define the ideal usability issue description:&lt;/p&gt;
&lt;p&gt;A usability issue should include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A description of the interface property that causes the problem.&lt;/strong&gt; We need to describe how the problematic element works, as it is the source of the issue.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;An explanation of why this system behavior is problematic.&lt;/strong&gt; This allows us to describe the problem&amp;rsquo;s mechanism and argue why we consider it a usability issue. It’s especially important to outline the participant’s actions with the problematic element that lead to difficulties.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A description of the problem’s impact on usability.&lt;/strong&gt; By definition, usability issues reduce key usability metrics, and it’s essential to demonstrate this negative impact.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can further illustrate the usability issue with participant quotes and add recommendations for resolution.&lt;/p&gt;
&lt;p&gt;As we see, participant opinions are not the essence of a usability issue but its illustration. This is particularly important because the object of our study is the interface, not the user.&lt;/p&gt;
&lt;p&gt;By strictly adhering to the constraints of usability testing, conducting and processing results will take significantly less time and resources compared to in-depth interviews. This is why I believe usability testing should be as simple as a hammer. Its strength lies in these limitations.&lt;/p&gt;
&lt;p&gt;In this article, I’ve tried to thoroughly describe my understanding of usability testing and the description of its results. As with everything I write, this represents my personal professional opinion rather than a textbook or objective truth. In any case, feel free to write to me and share feedback — I always enjoy and appreciate reading it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Guerilla Testing — How Not to Shoot Yourself in the Foot</title>
      <link>/en/post/guerilla-testing/</link>
      <pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate>
      <guid>/en/post/guerilla-testing/</guid>
      <description>&lt;p&gt;Guerilla testing is a controversial topic. Many researchers dislike it, and for good reasons.&lt;/p&gt;
&lt;p&gt;Guerilla tests are very superficial—you don’t have the time to talk to a person long enough. You can forget about a remotely representative sample, and the target audience rarely walks around the office.&lt;/p&gt;
&lt;p&gt;The sample size is small due to format limitations, and you don’t have the opportunity to ask about anything even moderately complex.&lt;/p&gt;
&lt;p&gt;Still, some people continue to use it. Why? Because it’s quick, simple, and gives you the illusion of being informed. It feels like you’ve talked to people, listened to opinions—what’s not to like?&lt;/p&gt;
&lt;p&gt;We can’t completely avoid guerilla testing, but as researchers, we can provide our colleagues with advice on making it at least somewhat useful. I’ve prepared 12 cards with tips to help smooth out most of the downsides of guerilla tests.&lt;/p&gt;
&lt;h2 id=&#34;section-1-goals-and-objectives-of-guerilla-testing&#34;&gt;Section 1: Goals and Objectives of Guerilla Testing&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;1.png&#34; alt=&#34;Goals and Objectives&#34;&gt;&lt;/p&gt;
&lt;p&gt;First, let’s clarify what value guerilla tests can actually provide. We won’t learn more about the target audience. We can’t extract opinions, user problems, or feature requests from them. However, we can test the application’s interface to see if there are any obvious design flaws.&lt;/p&gt;
&lt;p&gt;Even if the person isn’t part of our target audience, their misunderstanding of the interface can signal to us: “Aha, something’s wrong here; we should fix it.” The exception is professional products that require specialized knowledge or education to use. Guerilla testing won’t work for a nuclear power plant interface. But for a content consumption app? Absolutely.&lt;/p&gt;
&lt;p&gt;Text is a special case. On one hand, we can test the perception of phrases and terms. On the other hand, we must be extra careful to avoid specialized text. If our goal is to make the text understandable for everyone, it’s worth trying. If not, it’s better to skip guerilla testing.&lt;/p&gt;
&lt;h2 id=&#34;section-2-selecting-respondents&#34;&gt;Section 2: Selecting Respondents&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;2.png&#34; alt=&#34;Respondents&#34;&gt;&lt;/p&gt;
&lt;p&gt;Our sample will inevitably be ad hoc, but there are still some things to consider.&lt;/p&gt;
&lt;p&gt;First, obviously, don’t test on anyone who has any connection to the product being tested. Our goal is to find people who have never seen it, never participated in discussions, and ideally don’t even know it exists. We need fresh eyes, so we can skip our own team.&lt;/p&gt;
&lt;p&gt;Respondent rotation remains important. Avoid testing the same person twice, even with different prototypes. Playing favorites with respondents doesn’t lead to anything good, regardless of the study type.&lt;/p&gt;
&lt;p&gt;Ideally, we’d test with people entirely unrelated to the tech industry. Cleaners, security staff, and other support personnel are perfect for us. At the other end of the spectrum are designers and management—they see interfaces daily and are likely too experienced to provide a fresh perspective.&lt;/p&gt;
&lt;p&gt;Personally, I’d be a bad respondent—over the years, I’ve encountered products so poorly designed that I’ve developed a skill for understanding even the most baffling interface solutions :)&lt;/p&gt;
&lt;h2 id=&#34;section-3-formulating-tasks&#34;&gt;Section 3: Formulating Tasks&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;3.png&#34; alt=&#34;Tasks&#34;&gt;&lt;/p&gt;
&lt;p&gt;Guerilla testing can easily be mistaken for quantitative research—it’s tempting to count responses and conclude one interface is better than another. In reality, it doesn’t work that way. We can’t compare test results like this. While it may look like a quantitative survey, the insights are purely qualitative—potential usability issues to watch for. So let’s not compare prototypes head-to-head; it’s not great practice even in full-scale usability tests.&lt;/p&gt;
&lt;p&gt;We don’t have time to immerse participants in the testing context. We can’t spend time explaining our goals or using icebreakers. Therefore, tasks must be as short and clear as possible—like remote usability testing, but even more concise and straightforward.&lt;/p&gt;
&lt;p&gt;Standard research question requirements still apply: avoid leading questions, steer clear of “yes/no” questions, maintain neutrality, and account for socially desirable answers—few people want to upset a colleague.&lt;/p&gt;
&lt;h2 id=&#34;section-4-testing&#34;&gt;Section 4: Testing&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;4.png&#34; alt=&#34;Testing&#34;&gt;&lt;/p&gt;
&lt;p&gt;Guerilla testing has strict time limits. We can’t take up too much of someone’s workday. Therefore, it’s best to limit each participant to 1–2 tasks.&lt;/p&gt;
&lt;p&gt;As mentioned, numbers don’t matter in guerilla testing. As they say, you don’t need to wait for a hundred cars to drive over a pothole to know it needs fixing. If we notice repeated incorrect responses, two things are clear:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There are people who find something confusing.&lt;/li&gt;
&lt;li&gt;This isn’t a unique case; there are definitely more of them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are red flags and additional arguments for improving the solution.&lt;/p&gt;
&lt;p&gt;Oh, and yes, don’t show desktop applications on a mobile device. You could run around with printouts, but the ideal approach is to display the interface on the device it’s meant for.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Thank you for reading to the end—I hope you found this helpful. Modern product development methods push us toward fast and cheap approaches. But speed and cost-efficiency come with drawbacks: we gather less information and draw fewer conclusions. Those conclusions are less reliable. The most important thing, in my opinion, is to clearly understand the boundaries of what we’re doing. Otherwise, we risk making significant mistakes.&lt;/p&gt;
&lt;p&gt;You can download the PDF with cards &lt;a href=&#34;https://github.com/UXRozum/Hall-tests&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;on my GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
