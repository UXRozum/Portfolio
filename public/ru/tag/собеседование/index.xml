<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Собеседование | Rozum S, UXR</title>
    <link>/ru/tag/%D1%81%D0%BE%D0%B1%D0%B5%D1%81%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5/</link>
      <atom:link href="/ru/tag/%D1%81%D0%BE%D0%B1%D0%B5%D1%81%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5/index.xml" rel="self" type="application/rss+xml" />
    <description>Собеседование</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>ru</language><copyright>2025</copyright><lastBuildDate>Fri, 05 Mar 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu19a1120d39a533b4446980715d7e8190_15602_512x512_fill_lanczos_center_2.png</url>
      <title>Собеседование</title>
      <link>/ru/tag/%D1%81%D0%BE%D0%B1%D0%B5%D1%81%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5/</link>
    </image>
    
    <item>
      <title>Вопросы к исследователю, на собеседовании и в работе</title>
      <link>/ru/post/hiring-researchers/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      <guid>/ru/post/hiring-researchers/</guid>
      <description>&lt;p&gt;Недавно наткнулся на интересную статью 2016 года, где разбираются вопросы с собеседований на роль UX-исследователя в крупные западные компании. И некоторые вопросы мне прям очень понравились.&lt;/p&gt;
&lt;p&gt;Например:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Представьте, что вы дали рекомендацию по исправлению юзабилити-проблемы, но разработчик ответил “Данные метрик от миллионов пользователей говорят нам, что такой проблемы нет” Как вы ему ответите?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Этот вопрос прекрасен, он показывает ситуацию, в которой может оказаться любой исследователь, и при этом в ней есть второе дно, подвох. Этот вопрос отлично раскрывает проблемное место в нашей с вами отрасли, показывает важное противоречие.&lt;/p&gt;
&lt;p&gt;И правда, каким образом данные аналитики могут показать отсутствие юзабилити-проблемы? Особенно если на тесте мы своими глазами видим, как респонденты с ней сталкиваются. Какого рода данные могут опровергнуть это? Отсутствие отвалов пользователей на этом экране? Может быть скорость, с которой пользователи проходят этот экран, нисколько не снижается, по сравнению с остальными страницами? Возможно, были данные метрик до проведения редизайна, с которым можно сравнить.&lt;/p&gt;
&lt;p&gt;Насколько вообще исследователь должен быть уверен в своих инсайтах и решениях? Может ли он объяснить разработчику разницу между доказательством наличия и доказательством отсутствия? А должна ли юзабилити-проблема всегда быть видной на метриках? Как механизм триангуляции качественных и количественных данных будет работать на опровержение? Чем больше думаешь над ответом, и тем больше вопросов у тебя возникает. Если честно, я в восторге.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Мне кажется, что жанр вопросов на интервью — золотая жила. Ведь именно разрешая подобные ситуации, мы растем как исследователи и как индустрия. Задавая такие вопросы, мы рефлексируем, обращаем исследовательский взгляд на самих исследователей.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Я решил попробовать написать еще несколько подобных вопросов с подвохом. Давайте попробуем ответить на них вместе:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Аркадий хочет провести количественный опрос пользователей приложения, чтобы замерить UMUX. Владелец продукта предложил ему набрать равное количество опытных и неопытных пользователей, чтобы повысить репрезентативность. Насколько это предложение корректно?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ирина не может выбрать метод исследования. С одной стороны, она хотела бы провести глубинные интервью. Но менеджер продукта настаивает на проведении custdev. Как ей выйти из этого неудобного положения?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Вся команда в течение недели собирала для Николая гипотезы на проверку. Многие из них Николай смог раскидать в бэклог исследований, но одна из оставшихся не дает ему покоя. “В приложении появится возможность сортировать новости по количеству лайков от читателей”. Как бы вы проверяли такую гипотезу на месте Николая?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Во время проведения юзабилити-теста приложения для просмотра картинок Прокофий вдруг понял, что часть респондентов не понимают особенности работы системы. На следующий тест он позвал с собой разработчика, что бы тот мог объяснить пользователю тонкости фреймворка, на котором написано приложение. Как бы вы поступили на месте Прокофия?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Геннадий уже две недели пишет отчет о проведенных им 5 решенческих интервью. Материала набралось тонна, в презентации уже 150 слайдов. Сейчас он пишет уже 5 слайд о том, почему респондент №3 ни за что не будет пользоваться исследуемым продуктом. Ведь респондент четко сказал, что приложение ему не нравится. Как помочь Геннадию дописать отчет быстрее?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Михаил провел прекрасную презентацию отчета о юзабилити-тесте. Проблемы максимальной критичности режут глаз, дизайнер заплакал, увидев запись действий пользователя. Однако, как оказалось, исследуемую фичу уже убрали из продукта. Случилось это примерно тогда, когда Михаил начал проводить первое интервью. Что может Михаил сделать в следующий раз, чтобы не попасть в подобную ситуацию?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Как бы вы ответили на эти вопросы? А какой бы вы спросили сами, чтобы подсветить важную для вас проблему в индустрии UX-исследований?&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
